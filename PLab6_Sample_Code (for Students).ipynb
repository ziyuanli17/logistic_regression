{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "hw3_code.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyPIe/HzMLpv7tQhj5BwpQ/r"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLbL-LlnOAgm",
    "colab_type": "text"
   },
   "source": [
    "# PLab 6 Sample Code for Students"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0aSWrpaElDM0",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Add import statements here\n",
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "from scipy import stats"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TDvZ5xhsl9XM",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Part of the code was Adapted from CSE417T (Raviv, 2020)\n",
    "# Note: students attending this lab should complete the missing code following the hints and intro."
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Hi_dRrJDmtiI",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# To access files in your Google Drive, run this block and follow the instructions\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# To test if the above block worked, run this block\n",
    "# !ls '/content/gdrive/My Drive/'"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1rrY8fIxz7h",
    "colab_type": "text"
   },
   "source": [
    " ## Find test error\n",
    "\n",
    "The `find_test_error` function computes the test error of a linear classifier $w$. \n",
    "\n",
    "The hypothesis is assumed to be of the form $sign([1, x(N,:)] \\cdot w)$.\n",
    "\n",
    "Inputs:\n",
    "* `w` is the weight vector\n",
    "* `X` is the data matrix (without an initial column of 1's)\n",
    "* `y` are the data labels (plus or minus 1)\n",
    "\n",
    "Outputs:\n",
    "* `test_error` is the binary error of $w$ on the data set $(X, y)$ error; this should be between 0 and 1. \n",
    "\n",
    "Hint1: > 50 % is 1 (having heart disease) or -1 otherwise\n",
    "Hint2: if the prediction of your model (sig) does not agree with y, it's an error. \n",
    "Hint3: To find test_error, You need to divide error by total numbers of rows."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0BCKbvjMlHtE",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def find_test_error(w, X, y):\n",
    "    # Find the sigmoid distribution\n",
    "    sig = np.exp(np.dot(X, w))/(1+np.exp(np.dot(X, w)))\n",
    "    # Determine binary classification result \n",
    "    C = 0.5\n",
    "    # Complete the missing code here\n",
    "\n",
    "\n",
    "\n",
    "    # Determine binary classification error\n",
    "    error_sum = 0\n",
    "    # Complete the missing code here\n",
    "\n",
    "\n",
    "\n",
    "    return test_error"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUF6Mr1V0S5T",
    "colab_type": "text"
   },
   "source": [
    " ## Logistic Regression\n",
    "\n",
    "The `logistic_reg`  learn a logistic regression model using gradient descent.\n",
    "\n",
    "Inputs:\n",
    "* `X` is the data matrix (without an initial column of 1's)\n",
    "* `y` are the data labels (plus or minus 1)\n",
    "* `w_init` is the initial value of the w vector ($d+1$ dimensional)\n",
    "* `max_its` is the maximum number of iterations to run for\n",
    "* `eta` is the learning rate\n",
    "\n",
    "Outputs:\n",
    "* t is the number of iterations gradient descent ran for\n",
    "* w is the learned weight vector\n",
    "* e_in is the in-sample (cross-entropy) error "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dTcJkPE6lHvg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def logistic_reg(X, y, w_init, max_its, eta, thresh): # According to TA, “You could edit the function to take in that threshold value.” I can also use global var but this is bad in python\n",
    "    # Define parameters that might be useful for you\n",
    "    N=len(X)\n",
    "    w=w_init\n",
    "    t=0\n",
    "    while t < max_its:\n",
    "        \n",
    "        \n",
    "        # Implement logistic regression here\n",
    "\n",
    "       \n",
    "\n",
    "        # Test termination\n",
    "        mag_g_t = abs(g_t)\n",
    "        if all(m < thresh for m in mag_g_t):\n",
    "            break\n",
    "\n",
    "        # Update weight\n",
    "        v_t = -g_t\n",
    "        w = w+eta*v_t # Here is when the learning rate play roles\n",
    "        t+=1\n",
    "\n",
    "    # Calculate the cross-entropy in-sample error\n",
    "    e_in = []\n",
    "    for n in range(N):\n",
    "        e_in.append(np.log((1+np.exp(-y[n][0]*np.dot(w, X[n])))))\n",
    "    e_in = np.mean(e_in)\n",
    "    return t, w, e_in"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7d-boqb0y_H",
    "colab_type": "text"
   },
   "source": [
    "## Run and Plot\n",
    "\n",
    "Run your code and plot figures below"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FWHPRXv4lHx6",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Read files using csv library (function defined to prevent repeatedness)\n",
    "def read_csv(file_name):\n",
    "    set=[]\n",
    "    # Read file\n",
    "    with open(file_name, 'r') as f:\n",
    "        file = list(csv.reader(f))[1:]\n",
    "        # Convert values\n",
    "        for l in file:\n",
    "            row = []\n",
    "            for n in l:\n",
    "                try:\n",
    "                    row.append(int(n))\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        row.append(float(n))\n",
    "                    except ValueError:\n",
    "                        print(\"Unexpected value\")\n",
    "                        exit(1)\n",
    "            set.append(row)\n",
    "    return set\n",
    "\n",
    "# Split into X and y\n",
    "def split_X_y(set):\n",
    "    X = []\n",
    "    y = []\n",
    "    for r in set:\n",
    "        X.append([1]+r[0:-1])\n",
    "        y.append([r[-1]])\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == [0]:\n",
    "            y[i] = [-1]\n",
    "    return X, y\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Read training and testing files\n",
    "    train_set = read_csv(\"cleveland_train.csv\")\n",
    "    test_set = read_csv(\"cleveland_test.csv\")\n",
    "\n",
    "    # Get X and y for training\n",
    "    X = np.array(split_X_y(train_set)[0])\n",
    "    y = np.array(split_X_y(train_set)[1])\n",
    "\n",
    "    # Get X and y for testing\n",
    "    X_t = np.array(split_X_y(test_set)[0])\n",
    "    y_t = np.array(split_X_y(test_set)[1])\n",
    "\n",
    "\n",
    "    # Experiment with iterations\n",
    "    # Define input parameters\n",
    "    eta_0 = 0.00001\n",
    "    w_init = np.zeros(len(X[0]))\n",
    "    \n",
    "    \n",
    "    # Define your list of iterations here\n",
    "    \n",
    "    \n",
    "    print(\"Experimenting with iterations...\\n\")\n",
    "    for iter in iterations:\n",
    "        # Start training\n",
    "        start = time.time()\n",
    "        t, w, e_in = logistic_reg(X, y, w_init, iter, eta_0, 0.001)\n",
    "        end = time.time()\n",
    "\n",
    "        # Start testing\n",
    "        test_error = find_test_error(w, X_t, y_t)\n",
    "        training_error = find_test_error(w, X, y)\n",
    "\n",
    "        # Print out the results\n",
    "        print('Number of iterations: {}, Training time : {}s, In-sample Cross-Entropy error (Ein): {}, Binary error on the training set (Etrain): {}, Binary error on the test set (Etest): {} \\n'.format(t,round(end - start, 5), round(e_in, 5), round(training_error, 5), round(test_error, 5)))\n",
    "\n",
    "\n",
    "    # Experiment with learning rate\n",
    "    \n",
    "    \n",
    "    # Define your list of learning rates here\n",
    "    \n",
    "\n",
    "    # Find z-scores to normalize\n",
    "    ZX = np.append(np.ones((len(X), 1)), stats.zscore(X[:,1:]), axis=1)\n",
    "    ZX_t = np.append(np.ones((len(X_t), 1)), stats.zscore(X_t[:,1:]), axis=1)\n",
    "\n",
    "    print(\"Experimenting with learning rates...\\n\")\n",
    "    for eta_0 in eta_0s:\n",
    "        # Start training\n",
    "        # Using iterative termination condition of inf is equivalent to no iterations-based termination criteria\n",
    "        # Only terminate when the magnitude of every element of the gradient is less than 10^−6\n",
    "        start = time.time()\n",
    "        t, w, e_in = logistic_reg(ZX, y, w_init, float(\"inf\"), eta_0, 0.000001)\n",
    "        end = time.time()\n",
    "\n",
    "        # Start testing\n",
    "        test_error = find_test_error(w, ZX_t, y_t)\n",
    "\n",
    "        # Print out the results\n",
    "        print('Learning rate (η0): {}, Number of iterations: {}, Training time : {}s, In-sample cross-Entropy error (Ein): {}, Binary error on the test set (Etest): {} \\n'.format(eta_0, t, round(end - start, 5), round(e_in, 5), round(test_error, 5)))"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Z3mrOrbBLQuC",
    "colab_type": "code",
    "colab": {}
   },
   "source": [],
   "execution_count": 12,
   "outputs": []
  }
 ]
}
